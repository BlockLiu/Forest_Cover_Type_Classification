{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset: \n",
    "https://archive.ics.uci.edu/ml/datasets/covertype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabarish\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import ensemble\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Downloaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('covtype.data',header=None) # This is the base file downloaded\n",
    "\n",
    "#data = pd.read_csv('covtype_reduced.csv',header=0) #This file contains data reduced through Reverse 'One-Hot' Encoding for Soil type and wilderness area feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data as 80/20 for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabarish\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#data split for Base Data\n",
    "train_x, test_x, train_y, test_y = train_test_split(data.iloc[:,0:54].values,\n",
    "                                                        data.iloc[:,54:55].values.ravel(), train_size=0.8, random_state=44)\n",
    "\n",
    "#data split while using reduced features\n",
    "#train_x, test_x, train_y, test_y = train_test_split(data.iloc[:,0:12].values,\n",
    "#                                                        data.iloc[:,12:13].values.ravel(), train_size=0.8, random_state=44)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization using standardscaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabarish\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(464809, 54)\n",
      "(116203, 54)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_train_x = scaler.fit_transform(train_x)\n",
    "scaled_test_x = scaler.transform(test_x)\n",
    "print(scaled_train_x.shape)\n",
    "print(scaled_test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "(464809, 43)\n",
      "(116203, 43)\n"
     ]
    }
   ],
   "source": [
    "pca=PCA(.95) #scikit-learn choose the minimum number of principal components such that 95% of the variance is retained\n",
    "\n",
    "pca.fit(scaled_train_x)\n",
    "\n",
    "print(pca.n_components_)\n",
    "\n",
    "train_x_pca = pca.transform(scaled_train_x)\n",
    "test_x_pca = pca.transform(scaled_test_x)\n",
    "\n",
    "print(train_x_pca.shape)\n",
    "print(test_x_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search to tune parameters for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#Grid Search\n",
    "parameters = {'multi_class':('crammer_singer','ovr'),'C':[1, 0.1], 'loss':('hinge','squared_hinge')}\n",
    "\n",
    "C = 1  # SVM regularization parameter\n",
    "model = LinearSVC(random_state=0)\n",
    "cls = GridSearchCV(model, parameters)\n",
    "#print(cls)\n",
    "cls.fit(scaled_train_x, train_y)\n",
    "\n",
    "print('Best parameters for the model', cls.best_params_)\n",
    "\n",
    "y = cls.predict(scaled_test_x)\n",
    "\n",
    "print('test accuracy SVM: ', metrics.accuracy_score(test_y.ravel(),y))\n",
    "print('train accuracy SVM: ', cls.score(scaled_train_x, train_y))\n",
    "    \n",
    "print(\"computation time=--- %s seconds ---\" % (time.time() - start_time))\n",
    "#C=1 test accuracy SVM:  0.711471079531\n",
    "#C=1 train accuracy SVM:  0.708537005164"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters for the model {'C': 1, 'multi_class': 'crammer_singer', 'loss': 'hinge'}\n",
    "\n",
    "test accuracy SVM:  0.72369837054\n",
    "\n",
    "train accuracy SVM:  0.722788296041"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model with Tuned Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.70      0.71     42219\n",
      "          2       0.75      0.80      0.77     56617\n",
      "          3       0.66      0.87      0.75      7120\n",
      "          4       0.51      0.42      0.46       554\n",
      "          5       0.20      0.01      0.01      1992\n",
      "          6       0.57      0.09      0.15      3518\n",
      "          7       0.70      0.54      0.61      4183\n",
      "\n",
      "avg / total       0.71      0.72      0.71    116203\n",
      "\n",
      "test accuracy SVM:  0.723131072348\n",
      "train accuracy SVM:  0.724256630143\n",
      "computation time=--- 1649.6820979118347 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "C = 1  # SVM regularization parameter\n",
    "cls = LinearSVC(random_state=0, multi_class= 'crammer_singer', loss = 'hinge')\n",
    "cls.fit(scaled_train_x, train_y)\n",
    "\n",
    "y = cls.predict(scaled_test_x)\n",
    "\n",
    "print(metrics.classification_report(test_y.ravel(),y))\n",
    "print('test accuracy SVM: ', metrics.accuracy_score(test_y.ravel(),y))\n",
    "print('train accuracy SVM: ', cls.score(scaled_train_x, train_y))\n",
    "\n",
    "print(\"computation time=--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search to find optimal parameters for Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search\n",
    "start_time = time.time()\n",
    "\n",
    "parameters = {'class_weight':('balanced', 'balanced_subsample'),'n_estimators':[250, 300, 350], 'n_jobs':[-1,2]}\n",
    "\n",
    "model = ensemble.RandomForestClassifier(random_state=44)\n",
    "cls = GridSearchCV(model, parameters)\n",
    "cls.fit(train_x, train_y)\n",
    "\n",
    "print('Best parameters for the model', cls.best_params_)\n",
    "\n",
    "y = cls.predict(test_x)\n",
    "\n",
    "print('test accuracy', metrics.accuracy_score(test_y.ravel(),y))\n",
    "\n",
    "y_train_rf = cls.predict(train_x)\n",
    "print(metrics.classification_report(train_y.ravel(),y_train_rf))\n",
    "print('train accuracy', metrics.accuracy_score(train_y.ravel(),y_train_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters for the model {'class_weight': 'balanced', 'n_estimators': 300, 'n_jobs': -1}\n",
    "\n",
    "test accuracy SVM: 0.72369837054\n",
    "\n",
    "train accuracy SVM: 0.722788296041"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model with the Tuned Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.97      0.95      0.96     42219\n",
      "          2       0.95      0.98      0.96     56617\n",
      "          3       0.94      0.96      0.95      7120\n",
      "          4       0.92      0.88      0.90       554\n",
      "          5       0.94      0.79      0.86      1992\n",
      "          6       0.94      0.90      0.92      3518\n",
      "          7       0.98      0.95      0.96      4183\n",
      "\n",
      "avg / total       0.96      0.96      0.96    116203\n",
      "\n",
      "test accuracy 0.95676531587\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00    169621\n",
      "          2       1.00      1.00      1.00    226684\n",
      "          3       1.00      1.00      1.00     28634\n",
      "          4       1.00      1.00      1.00      2193\n",
      "          5       1.00      1.00      1.00      7501\n",
      "          6       1.00      1.00      1.00     13849\n",
      "          7       1.00      1.00      1.00     16327\n",
      "\n",
      "avg / total       1.00      1.00      1.00    464809\n",
      "\n",
      "train accuracy 1.0\n",
      "computation time=--- 296.1732907295227 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Train and predict with the random forest classifier\n",
    "rf = ensemble.RandomForestClassifier(n_estimators=300, class_weight = 'balanced', n_jobs=-1, random_state=44)\n",
    "rf.fit(train_x,train_y.ravel())\n",
    "y = rf.predict(test_x)\n",
    "print(metrics.classification_report(test_y.ravel(),y))\n",
    "print('test accuracy', metrics.accuracy_score(test_y.ravel(),y))\n",
    "\n",
    "y_train_rf = rf.predict(train_x)\n",
    "print(metrics.classification_report(train_y.ravel(),y_train_rf))\n",
    "print('train accuracy', metrics.accuracy_score(train_y.ravel(),y_train_rf))\n",
    "\n",
    "print(\"computation time=--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k fold cross valdation on random forest\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "start_time = time.time()\n",
    "k_fold = KFold(len(data.iloc[:,54:55].values.ravel()), n_folds=10, shuffle=True, random_state=44)\n",
    "\n",
    "cls = ensemble.RandomForestClassifier(n_estimators=300,class_weight='balanced',n_jobs=-1, random_state=44) #Ramdom Forest\n",
    "print (cross_val_score(cls, data.iloc[:,0:54].values, data.iloc[:,54:55].values.ravel(), cv=k_fold, n_jobs=1))\n",
    "\n",
    "print(\"computation time=--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[ 0.95969158  0.95924409  0.95858935  0.96099895  0.95919175  0.96020723\n",
    "  0.95778042  0.95752225  0.95946713  0.95907127]\n",
    "computation time=--- 1862.8303289413452 seconds ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.95      0.94      0.95     42219\n",
      "          2       0.95      0.97      0.96     56617\n",
      "          3       0.94      0.96      0.95      7120\n",
      "          4       0.92      0.86      0.89       554\n",
      "          5       0.94      0.77      0.84      1992\n",
      "          6       0.94      0.89      0.91      3518\n",
      "          7       0.97      0.95      0.96      4183\n",
      "\n",
      "avg / total       0.95      0.95      0.95    116203\n",
      "\n",
      "test accuracy 0.950035713364\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00    169621\n",
      "          2       1.00      1.00      1.00    226684\n",
      "          3       1.00      1.00      1.00     28634\n",
      "          4       1.00      1.00      1.00      2193\n",
      "          5       1.00      1.00      1.00      7501\n",
      "          6       1.00      1.00      1.00     13849\n",
      "          7       1.00      1.00      1.00     16327\n",
      "\n",
      "avg / total       1.00      1.00      1.00    464809\n",
      "\n",
      "train accuracy 1.0\n",
      "computation time=--- 59.12050747871399 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "start_time = time.time()\n",
    "\n",
    "# Train and predict with the random forest classifier\n",
    "forest = ExtraTreesClassifier(n_estimators=100,\n",
    "                              random_state=0)\n",
    "\n",
    "forest.fit(train_x, train_y.ravel())\n",
    "importances = forest.feature_importances_\n",
    "y = forest.predict(test_x)\n",
    "\n",
    "print(metrics.classification_report(test_y.ravel(),y))\n",
    "print('test accuracy', metrics.accuracy_score(test_y.ravel(),y))\n",
    "\n",
    "y_train_rf = forest.predict(train_x)\n",
    "print(metrics.classification_report(train_y.ravel(),y_train_rf))\n",
    "print('train accuracy', metrics.accuracy_score(train_y.ravel(),y_train_rf))\n",
    "\n",
    "print(\"computation time=--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k fold cross valdation on Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "k_fold = KFold(len(data.iloc[:,54:55].values.ravel()), n_folds=10, shuffle=True, random_state=44)\n",
    "\n",
    "cls = ExtraTreesClassifier(n_estimators=100,random_state=0)\n",
    "print (cross_val_score(cls, data.iloc[:,0:54].values, data.iloc[:,54:55].values.ravel(), cv=k_fold, n_jobs=1))\n",
    "\n",
    "print(\"computation time=--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ 0.95969158  0.95924409  0.95858935  0.96099895  0.95919175  0.96020723\n",
    "  0.95778042  0.95752225  0.95946713  0.95907127]\n",
    "computation time=--- 2531.3313714903211 seconds ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Due to the system limitations, grid search was not performed in Logistic Regression but were executed separately to get the accuracy of each parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression without scaling and pca #Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabarish\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy without scaling and pca:  0.732228915663\n",
      "Testing Accuracy without scalng and pca:  0.574958943798\n",
      "[2 2 2 ..., 3 3 3]\n",
      "[2 2 2 ..., 3 3 3]\n",
      "computation time=--- 63.02908754348755 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Train multinomial logistic regression model\n",
    "multinomial_class = linear_model.LogisticRegression(multi_class='multinomial', solver='newton-cg', max_iter = 100).fit(train_x, train_y.values.ravel())\n",
    " \n",
    "# predict and calculate accuracy in training data\n",
    "prob = multinomial_class.predict(train_x)\n",
    "prob_test = multinomial_class.predict(test_x)\n",
    "\n",
    "print ('Training Accuracy without scaling and pca: ',metrics.accuracy_score(train_y, prob)) \n",
    "print ('Testing Accuracy without scalng and pca: ',metrics.accuracy_score(test_y, prob_test)) \n",
    "\n",
    "print(prob_test)\n",
    "print(test_y)\n",
    "\n",
    "print(\"computation time=--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression without scaling and pca #ovr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy OVR without pca and scaling:  0.705388665022\n",
      "Testing Accuracy OVR without pca and scaling:  0.705850967703\n",
      "[3 2 2 ..., 2 3 2]\n",
      "        54\n",
      "240609   3\n",
      "333022   1\n",
      "375315   2\n",
      "453031   1\n",
      "229408   2\n",
      "381877   2\n",
      "290574   2\n",
      "519153   1\n",
      "365669   1\n",
      "45099    1\n",
      "232648   1\n",
      "75915    2\n",
      "127025   1\n",
      "248350   1\n",
      "570632   2\n",
      "541677   1\n",
      "170763   2\n",
      "547630   2\n",
      "530847   1\n",
      "121703   1\n",
      "356223   1\n",
      "525117   1\n",
      "438716   1\n",
      "284025   3\n",
      "423295   1\n",
      "466296   2\n",
      "547393   2\n",
      "140887   2\n",
      "67789    1\n",
      "195806   2\n",
      "...     ..\n",
      "37387    1\n",
      "474215   1\n",
      "221515   2\n",
      "386201   2\n",
      "37220    2\n",
      "541717   1\n",
      "444714   1\n",
      "564448   1\n",
      "65279    2\n",
      "574351   6\n",
      "318678   3\n",
      "47317    2\n",
      "517505   7\n",
      "114503   2\n",
      "259769   2\n",
      "61739    2\n",
      "539836   2\n",
      "244692   2\n",
      "321509   1\n",
      "9497     7\n",
      "54265    1\n",
      "569008   2\n",
      "82938    1\n",
      "126763   2\n",
      "370942   2\n",
      "305999   2\n",
      "526794   2\n",
      "91835    2\n",
      "371636   3\n",
      "172344   2\n",
      "\n",
      "[116203 rows x 1 columns]\n",
      "computation time=--- 248.20125651359558 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Train multinomial logistic regression model\n",
    "ovr_class = linear_model.LogisticRegression(multi_class='ovr', solver='newton-cg', max_iter = 100).fit(train_x, train_y.values.ravel())\n",
    "\n",
    "# predict and calculate accuracy in training data\n",
    "prob = ovr_class.predict(train_x)\n",
    "prob_test = ovr_class.predict(test_x)\n",
    "\n",
    "print ('Training Accuracy OVR without pca and scaling: ',metrics.accuracy_score(train_y, prob)) \n",
    "print ('Testing Accuracy OVR without pca and scaling: ',metrics.accuracy_score(test_y, prob_test)) \n",
    "\n",
    "print(prob_test)\n",
    "\n",
    "print(\"computation time=--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression with scaling and without pca #Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabarish\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy multinomial scaled data without pca:  0.72515377284\n",
      "Testing Accuracy multinomial scaled data without pca:  0.723294579314\n",
      "[2 2 2 ..., 1 1 2]\n",
      "computation time=--- 2873.342022418976 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Train multinomial logistic regression model\n",
    "multiscal_class = linear_model.LogisticRegression(multi_class='multinomial', solver='newton-cg', max_iter = 100).fit(scaled_train_x, train_y)\n",
    "\n",
    "# predict and calculate accuracy in training data\n",
    "prob = multiscal_class.predict(scaled_train_x)\n",
    "prob_test = multiscal_class.predict(scaled_test_x)\n",
    "\n",
    "print ('Training Accuracy multinomial scaled data without pca: ',metrics.accuracy_score(train_y, prob)) \n",
    "print ('Testing Accuracy multinomial scaled data without pca: ',metrics.accuracy_score(test_y, prob_test)) \n",
    "\n",
    "print(prob_test)\n",
    "\n",
    "print(\"computation time=--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression with scaling and without pca #ovr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy OVR scaled data without pca:  0.715872541194\n",
      "Testing Accuracy OVR scaled data without pca:  0.713492766968\n",
      "computation time=--- 256.93520402908325 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Train multinomial logistic regression model\n",
    "ovrscal_class = linear_model.LogisticRegression(multi_class='ovr', solver='liblinear', max_iter = 100).fit(scaled_train_x, train_y.values.ravel())\n",
    "\n",
    "# predict and calculate accuracy in training data\n",
    "prob = ovrscal_class.predict(scaled_train_x)\n",
    "prob_test = ovrscal_class.predict(scaled_test_x)\n",
    "\n",
    "print ('Training Accuracy OVR scaled data without pca: ',metrics.accuracy_score(train_y, prob)) \n",
    "print ('Testing Accuracy OVR scaled data without pca: ',metrics.accuracy_score(test_y, prob_test)) \n",
    "\n",
    "print(prob_test)\n",
    "\n",
    "print(\"computation time=--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression with scaling and pca #Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy multinomial scaled data &  pca:  0.7225785215\n",
      "Testing Accuracy multinomial scaled data & pca:  0.722184453069\n",
      "[3 2 2 ..., 2 3 2]\n",
      "        54\n",
      "240609   3\n",
      "333022   1\n",
      "375315   2\n",
      "453031   1\n",
      "229408   2\n",
      "381877   2\n",
      "290574   2\n",
      "519153   1\n",
      "365669   1\n",
      "45099    1\n",
      "232648   1\n",
      "75915    2\n",
      "127025   1\n",
      "248350   1\n",
      "570632   2\n",
      "541677   1\n",
      "170763   2\n",
      "547630   2\n",
      "530847   1\n",
      "121703   1\n",
      "356223   1\n",
      "525117   1\n",
      "438716   1\n",
      "284025   3\n",
      "423295   1\n",
      "466296   2\n",
      "547393   2\n",
      "140887   2\n",
      "67789    1\n",
      "195806   2\n",
      "...     ..\n",
      "37387    1\n",
      "474215   1\n",
      "221515   2\n",
      "386201   2\n",
      "37220    2\n",
      "541717   1\n",
      "444714   1\n",
      "564448   1\n",
      "65279    2\n",
      "574351   6\n",
      "318678   3\n",
      "47317    2\n",
      "517505   7\n",
      "114503   2\n",
      "259769   2\n",
      "61739    2\n",
      "539836   2\n",
      "244692   2\n",
      "321509   1\n",
      "9497     7\n",
      "54265    1\n",
      "569008   2\n",
      "82938    1\n",
      "126763   2\n",
      "370942   2\n",
      "305999   2\n",
      "526794   2\n",
      "91835    2\n",
      "371636   3\n",
      "172344   2\n",
      "\n",
      "[116203 rows x 1 columns]\n",
      "computation time=--- 1604.5519785881042 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Train multinomial logistic regression model\n",
    "multiscalpca_class = linear_model.LogisticRegression(multi_class='multinomial', solver='newton-cg', max_iter = 100).fit(train_x_pca, train_y.values.ravel())\n",
    "\n",
    "# predict and calculate accuracy in training data\n",
    "prob = multiscalpca_class.predict(train_x_pca)\n",
    "prob_test = multiscalpca_class.predict(test_x_pca)\n",
    "\n",
    "print ('Training Accuracy multinomial scaled data &  pca: ',metrics.accuracy_score(train_y, prob)) \n",
    "print ('Testing Accuracy multinomial scaled data & pca: ',metrics.accuracy_score(test_y, prob_test)) \n",
    "\n",
    "print(prob_test)\n",
    "\n",
    "print(\"computation time=--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression with scaling and pca #OVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy OVR scaled data &  pca:  0.705388665022\n",
      "Testing Accuracy OVR scaled data & pca:  0.705850967703\n",
      "[3 2 2 ..., 2 3 2]\n",
      "        54\n",
      "240609   3\n",
      "333022   1\n",
      "375315   2\n",
      "453031   1\n",
      "229408   2\n",
      "381877   2\n",
      "290574   2\n",
      "519153   1\n",
      "365669   1\n",
      "45099    1\n",
      "232648   1\n",
      "75915    2\n",
      "127025   1\n",
      "248350   1\n",
      "570632   2\n",
      "541677   1\n",
      "170763   2\n",
      "547630   2\n",
      "530847   1\n",
      "121703   1\n",
      "356223   1\n",
      "525117   1\n",
      "438716   1\n",
      "284025   3\n",
      "423295   1\n",
      "466296   2\n",
      "547393   2\n",
      "140887   2\n",
      "67789    1\n",
      "195806   2\n",
      "...     ..\n",
      "37387    1\n",
      "474215   1\n",
      "221515   2\n",
      "386201   2\n",
      "37220    2\n",
      "541717   1\n",
      "444714   1\n",
      "564448   1\n",
      "65279    2\n",
      "574351   6\n",
      "318678   3\n",
      "47317    2\n",
      "517505   7\n",
      "114503   2\n",
      "259769   2\n",
      "61739    2\n",
      "539836   2\n",
      "244692   2\n",
      "321509   1\n",
      "9497     7\n",
      "54265    1\n",
      "569008   2\n",
      "82938    1\n",
      "126763   2\n",
      "370942   2\n",
      "305999   2\n",
      "526794   2\n",
      "91835    2\n",
      "371636   3\n",
      "172344   2\n",
      "\n",
      "[116203 rows x 1 columns]\n",
      "computation time=--- 266.72931575775146 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Train multinomial logistic regression model\n",
    "ovrscalpca_class = linear_model.LogisticRegression(multi_class='ovr', solver='newton-cg', max_iter = 200).fit(train_x_pca, train_y.values.ravel())\n",
    "\n",
    "# predict and calculate accuracy in training data\n",
    "prob = ovrscalpca_class.predict(train_x_pca)\n",
    "prob_test = ovrscalpca_class.predict(test_x_pca)\n",
    "\n",
    "print ('Training Accuracy OVR scaled data &  pca: ',metrics.accuracy_score(train_y, prob)) \n",
    "print ('Testing Accuracy OVR scaled data & pca: ',metrics.accuracy_score(test_y, prob_test)) \n",
    "\n",
    "print(prob_test)\n",
    "\n",
    "print(\"computation time=--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Fold cross validation for Naive Bayes Algorithm with optimal parameters\n",
    "\n",
    "#### Naive bayes have been executed for Gaussian and Bernoulli algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getmetrics(y_true, y_pred, algo,target_names):\n",
    "        from sklearn.metrics import explained_variance_score\n",
    "        from sklearn.metrics import mean_squared_error\n",
    "        from sklearn.metrics import mean_absolute_error\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        #from sklearn.metrics import confusion_matrix\n",
    "        from sklearn.metrics import classification_report\n",
    "        from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.45900313  0.45702385  0.45877007  0.45797835  0.45961343  0.46355484\n",
      "  0.45761691  0.45949295  0.45844306  0.46012977]\n",
      "[ 0.6325944   0.62832605  0.63558286  0.63434364  0.6332249   0.62969656\n",
      "  0.63012685  0.63270856  0.62935233  0.62900811]\n"
     ]
    }
   ],
   "source": [
    "target_names=['1 - Spruce/Fir', '2 - Lodgepole Pine', '3 - Ponderosa Pine', '4 - Cottonwood/Willow', '5 – Aspen', '6 - Douglas-fir', '7 – Krummholz']\n",
    "\n",
    "gnb = GaussianNB()\n",
    "y_gnb = gnb.fit(train_x, train_y).predict(test_x)\n",
    "\n",
    "getmetrics(test_y,y_gnb,'GaussianNB',target_names)\n",
    "\n",
    "st=time.time()\n",
    "\n",
    "##k fold for Gaussian\n",
    "k_fold = KFold(data.shape[0], n_folds=10, shuffle=True, random_state=44)\n",
    "cls = GaussianNB()\n",
    "print(cross_val_score(cls, data.iloc[:,0:54].values, data.iloc[:,54].values, cv=k_fold, n_jobs=1))\n",
    "\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "y_bnb = bnb.fit(train_x, train_y).predict(test_x)\n",
    "\n",
    "getmetrics(test_y,y_bnb,'BernoulliNB',target_names)\n",
    "\n",
    "st=time.time()\n",
    "##k fold for Bernoulli\n",
    "k_fold = KFold(data.shape[0], n_folds=10, shuffle=True, random_state=44)\n",
    "cls = BernoulliNB()\n",
    "print(cross_val_score(cls, data.iloc[:,0:54].values, data.iloc[:,54].values, cv=k_fold, n_jobs=1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
